```
# üöÄ ASHA - Your Helpful AI Assistant

**A Retrieval-Augmented Generation (RAG) Chatbot using Groq, LangChain, Pinecone, and Streamlit**

---

## üìú Overview
**ASHA** is a Retrieval-Augmented Generation (RAG) based chatbot designed to give intelligent, contextual answers.  
It uses **LangChain** to manage retrieval and generation, **Pinecone** for storing and querying vectors, **Groq API** for fast large language model (LLM) inference, and a **Streamlit** app for the frontend.

---

## üöÄ Features
- üîé **Contextual retrieval** of information using **Pinecone** vector database.
- ‚ö° **Groq-powered LLMs** (like Mixtral, LLaMA 3) generate human-like responses.
- üîó **LangChain** integration for flexible retrieval-generation workflows.
- üñ•Ô∏è **Streamlit UI** for a clean and interactive user experience.
- ‚öôÔ∏è Fast, intelligent, and memory-efficient design using Groq's low-latency APIs.

---

## üß© How it Works
1. **User inputs a query.**
2. **Pinecone** retrieves top relevant documents.
3. Retrieved context + query is formatted into a **custom prompt**.
4. **Groq LLM** generates a coherent, helpful answer.
5. The **Streamlit** app displays the response.

---

## üõ†Ô∏è Tech Stack
- **Python 3.10+**
- **LangChain**
- **Pinecone**
- **Groq Python SDK**
- **Streamlit**
- **FAISS** (optional for local retrieval without Pinecone)

---

## üìÇ Project Structure
```bash
.
‚îú‚îÄ‚îÄ app.py                # Main Streamlit application
‚îú‚îÄ‚îÄ chatbot/              
‚îÇ   ‚îú‚îÄ‚îÄ embed_text.py      # Text embedding utilities
‚îÇ   ‚îú‚îÄ‚îÄ load_data.py       # Load and prepare documents
‚îÇ   ‚îú‚îÄ‚îÄ groq_setup.py      # Load Groq LLM models
‚îÇ   ‚îú‚îÄ‚îÄ pinecone_setup.py  # Setup and manage Pinecone connection
‚îÇ   ‚îú‚îÄ‚îÄ prompt.py          # Build custom prompt templates
‚îÇ   ‚îú‚îÄ‚îÄ retrieval.py       # Retrieve context from Pinecone
‚îÇ   ‚îú‚îÄ‚îÄ split_text.py      # Text splitting into chunks
‚îÇ   ‚îú‚îÄ‚îÄ util.py            # Utility functions
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ .gitignore             # Files/folders to ignore by Git
‚îî‚îÄ‚îÄ .devcontainer/         # Dev container setup for VS Code (optional)
````

---

## üèóÔ∏è Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/rag-chatbot.git
cd rag-chatbot
```

### 2. Create Virtual Environment

```bash
python -m venv myenv
myenv\Scripts\activate  # On Windows
source myenv/bin/activate  # On Linux/Mac
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Set up Environment Variables

Create a `.env` file inside the `chatbot/` folder and add:

```ini
GROQ_API_KEY=your-groq-api-key
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_INDEX=your-pinecone-index-name
HUGGINGFACE_API_KEY=your-huggingface-api-key
```

### 5. Run the Streamlit App

```bash
streamlit run app.py
```

---

## üìö Example Query

> **User:** "What are the job opportunities for women in India?"

> **Bot:**
> "There are several job opportunities for women in India, especially in companies like Google, Accenture, and IBM. Positions like Human Resource Specialist, Software Developer, and Healthcare Professional are quite common."

---

## ‚ú® Future Improvements

* Add **chat history** (memory feature).
* Enable **switching between multiple LLMs** (Groq, GPT-4, custom LLMs).
* Add **authentication** for secure document uploads.
* Improve **UI/UX** with chat animations and avatars.

---

## üìù License

This project is licensed under the **MIT License**.
Feel free to use, modify, and distribute it!

---

## üôå Acknowledgements

* [LangChain](https://www.langchain.com/)
* [Pinecone](https://www.pinecone.io/)
* [Groq](https://groq.com/)
* [Streamlit](https://streamlit.io/)

```
```
